{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3.13. 丢弃法.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMOS2ffrJgwLfAVIylNqZKm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/liuxiao916/Dive_into_DL_PyTorch/blob/main/3_13_%E4%B8%A2%E5%BC%83%E6%B3%95.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4BzbHfp4H6GJ"
      },
      "source": [
        "## 3.13 丢弃法"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYx53JxkKvYJ"
      },
      "source": [
        "### 3.12.2 从零开始实现"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdmT5a8aHxOW"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "def dropout(X, drop_prob):\n",
        "    assert 0<=drop_prob<=1\n",
        "    keep_prob = 1- drop_prob\n",
        "    if keep_prob==0:\n",
        "        return torch.zeros_like(X)\n",
        "    mask = torch.tensor(np.random.uniform(0,1,X.shape)<keep_prob)\n",
        "    return mask*X/keep_prob"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0AkCmiEK2De",
        "outputId": "b2da3260-8dac-40ce-f902-9e425e006bfb"
      },
      "source": [
        "X = torch.arange(16).reshape((2,8))\n",
        "dropout(X, 0)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.],\n",
              "        [ 8.,  9., 10., 11., 12., 13., 14., 15.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pcBSfk-QNB5B",
        "outputId": "ebc29657-055d-4542-d99e-be85a37b50fd"
      },
      "source": [
        "dropout(X, 0.5)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.,  0.,  0.,  6.,  0.,  0.,  0., 14.],\n",
              "        [ 0.,  0.,  0., 22., 24.,  0.,  0., 30.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_2dnnB4nOEp7",
        "outputId": "a656d460-bd0e-4d83-b2b9-17ac1a2bf14c"
      },
      "source": [
        "dropout(X, 1)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tbLWwgcWOHR_"
      },
      "source": [
        "1. 定义模型参数"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UA-kJNPjOGPM"
      },
      "source": [
        "num_inputs, num_outputs, num_hiddens1,num_hiddens2 = 784, 10, 256, 256\n",
        "\n",
        "W1 = torch.tensor(np.random.normal(0, 0.01, size=(num_inputs, num_hiddens1)), dtype=torch.float, requires_grad=True)\n",
        "b1 = torch.zeros(num_hiddens1, requires_grad=True)\n",
        "W2 = torch.tensor(np.random.normal(0, 0.01, size=(num_hiddens1, num_hiddens2)), dtype=torch.float, requires_grad=True)\n",
        "b2 = torch.zeros(num_hiddens2, requires_grad=True)\n",
        "W3 = torch.tensor(np.random.normal(0, 0.01, size=(num_hiddens2, num_outputs)), dtype=torch.float, requires_grad=True)\n",
        "b3 = torch.zeros(num_outputs, requires_grad=True)\n",
        "\n",
        "params = [W1, b1, W2, b2, W3, b3]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_2PIxelQrDm"
      },
      "source": [
        "2. 定义模型"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "br8ORxKYQp5E"
      },
      "source": [
        "drop_prob1, drop_prob2 = 0.2, 0.5\n",
        "\n",
        "def net(X, is_training=True):\n",
        "    X = X.view(-1,num_inputs)\n",
        "    H1 = (torch.mm(X,W1)+b1).relu()\n",
        "    if is_training:\n",
        "        H1 = dropout(H1, drop_prob1)\n",
        "    H2 = (torch.mm(H1,W2)+b2).relu()\n",
        "    if is_training:\n",
        "        H2 = dropout(H2, drop_prob2)\n",
        "    return torch.mm(H2,W3) + b3"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-p67qkOARlDK"
      },
      "source": [
        "3. 训练和测试模型"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g_yM7esMRfKM",
        "outputId": "6fa66a9a-3d08-4ece-a400-5e20e98bd2e6"
      },
      "source": [
        "num_epochs, lr, Batch_size = 5, 0.5, 256\n",
        "loss = torch.nn.CrossEntropyLoss()\n",
        "import torchvision\n",
        "fashionmnist_train = torchvision.datasets.FashionMNIST(root = './data/fashionMNIST', train = True, transform=torchvision.transforms.ToTensor(),download=True)\n",
        "fashionmnist_train_dataloader = torch.utils.data.DataLoader(dataset= fashionmnist_train,batch_size = Batch_size, shuffle = True)\n",
        "fashionmnist_test = torchvision.datasets.FashionMNIST(root = './data/fashionMNIST', train = False, transform=torchvision.transforms.ToTensor(),download=True)\n",
        "fashionmnist_test_dataloader = torch.utils.data.DataLoader(dataset= fashionmnist_test,batch_size = Batch_size, shuffle = True)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)\n",
            "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_sp__NvfUqj0"
      },
      "source": [
        "def evaluate_accuracy(data_iter, net):\n",
        "    acc_sum, n = 0.0, 0 \n",
        "    for X,y in data_iter:\n",
        "        acc_sum += (net(X, is_training=False).argmax(dim=1) == y).float().sum().item() \n",
        "        n += y.shape[0]\n",
        "    return acc_sum/n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUb0YC6vVhHe"
      },
      "source": [
        "def sgd(params, lr):\n",
        "    for param in params:\n",
        "        param.data = param.data - lr*param.grad"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dSib5w5bQ22y",
        "outputId": "1e1ce91b-ff0c-4e3b-861b-04911a34e11d"
      },
      "source": [
        "def train_ch3_1(net, train_iter,test_iter, loss, num_epochs, batch_size, params = None, lr = None, optimizer=None):\n",
        "    for epoch in range(num_epochs):\n",
        "        train_l_sum, train_acc_sum, n =0.0, 0.0, 0\n",
        "        for X,y in train_iter:\n",
        "            y_hat = net(X)\n",
        "            l = loss(y_hat, y).sum()\n",
        "            l.backward()\n",
        "            sgd(params, lr)\n",
        "            \n",
        "            for param in params:\n",
        "                param.grad.data.zero_()\n",
        "\n",
        "            train_l_sum += l.item()\n",
        "            train_acc_sum += (y_hat.argmax(dim=1) == y).sum().item()\n",
        "            n += y.shape[0]\n",
        "        test_acc = evaluate_accuracy(test_iter, net)\n",
        "        print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f' % (epoch + 1, train_l_sum / n, train_acc_sum / n, test_acc))\n",
        "\n",
        "train_ch3_1(net, fashionmnist_train_dataloader, fashionmnist_test_dataloader, loss, num_epochs, Batch_size, params, lr) "
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 1, loss 0.0048, train acc 0.515, test acc 0.754\n",
            "epoch 2, loss 0.0024, train acc 0.768, test acc 0.805\n",
            "epoch 3, loss 0.0023, train acc 0.788, test acc 0.822\n",
            "epoch 4, loss 0.0019, train acc 0.824, test acc 0.839\n",
            "epoch 5, loss 0.0017, train acc 0.838, test acc 0.823\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1m_5ODOW_J7"
      },
      "source": [
        "### 3.13.3 简介实现"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sphIC57GVlfX"
      },
      "source": [
        "net = torch.nn.Sequential()\n",
        "net.add_module('Linear1', torch.nn.Linear(784,256))\n",
        "net.add_module('ReLU1',torch.nn.ReLU())\n",
        "net.add_module('Drop1',torch.nn.Dropout(drop_prob1))\n",
        "net.add_module('Linear2', torch.nn.Linear(256,256))\n",
        "net.add_module('ReLU2',torch.nn.ReLU())\n",
        "net.add_module('Drop2',torch.nn.Dropout(drop_prob2))\n",
        "net.add_module('Linear3', torch.nn.Linear(256,10))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "heSCf2TJX4lN"
      },
      "source": [
        "optimizer = torch.optim.SGD(net.parameters(), lr=0.5)\n",
        "\n",
        "def evaluate_accuracy_torch(data_iter, net):\n",
        "    acc_sum, n = 0.0, 0 \n",
        "    for X,y in data_iter:\n",
        "        net.eval()\n",
        "        acc_sum += (net(X.reshape(-1,num_inputs)).argmax(dim=1) == y).float().sum().item() \n",
        "        net.train()\n",
        "        n += y.shape[0]\n",
        "    return acc_sum/n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OmYouvtBX9Fk",
        "outputId": "9b0a12d9-1aaf-40ce-e34b-181914bdb235"
      },
      "source": [
        "num_epochs = 5\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    train_l_sum, train_acc_sum, n =0.0, 0.0, 0\n",
        "    for X,y in fashionmnist_train_dataloader:\n",
        "        y_hat = net(X.reshape(-1,num_inputs))\n",
        "        l = loss(y_hat, y).sum()\n",
        "        optimizer.zero_grad()\n",
        "        l.backward()\n",
        "        optimizer.step()\n",
        "        train_l_sum += l.item()\n",
        "        train_acc_sum += (y_hat.argmax(dim=1) == y).sum().item()\n",
        "        n += y.shape[0]\n",
        "    test_acc = evaluate_accuracy_torch(fashionmnist_test_dataloader, net)\n",
        "    print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f' % (epoch + 1, train_l_sum / n, train_acc_sum / n, test_acc))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 1, loss 0.0034, train acc 0.675, test acc 0.747\n",
            "epoch 2, loss 0.0021, train acc 0.805, test acc 0.810\n",
            "epoch 3, loss 0.0018, train acc 0.832, test acc 0.829\n",
            "epoch 4, loss 0.0017, train acc 0.843, test acc 0.803\n",
            "epoch 5, loss 0.0016, train acc 0.853, test acc 0.781\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "paohzDkJYR1q"
      },
      "source": [
        ""
      ],
      "execution_count": 13,
      "outputs": []
    }
  ]
}